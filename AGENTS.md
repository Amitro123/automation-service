# ü§ñ AGENTS.md - GitHub Automation Agent Instructions

Instructions for AI coding agents (Windsurf, Cursor, GitHub Copilot, etc.) working on this repository.

## üéØ Project Mission

**Single responsibility**: React to GitHub **push and pull request events** ‚Üí run parallel LLM-powered tasks:
1. **Code Review** ‚Üí post intelligent feedback (PR reviews or commit comments)
2. **README Update** ‚Üí detect changes ‚Üí create PR with docs
3. **Spec Update** ‚Üí append structured progress log
4. **Trivial Change Filter** ‚Üí skip automation for small/whitespace-only changes

**Success metric**: After every push/PR ‚Üí repo has fresh review + updated docs + progress log (unless trivial).

## üìÅ Project Structure

src/automation_agent/ # Core package
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ main.py # Flask entry point (python -m automation_agent.main)
‚îú‚îÄ‚îÄ main_api.py # FastAPI entry point
‚îú‚îÄ‚îÄ api_server.py # FastAPI server with Dashboard API
‚îú‚îÄ‚îÄ webhook_server.py # Flask webhook endpoint
‚îú‚îÄ‚îÄ orchestrator.py # Coordinates parallel tasks (push + PR events)
‚îú‚îÄ‚îÄ trigger_filter.py # Event classification + trivial change detection (NEW)
‚îú‚îÄ‚îÄ session_memory.py # Session Memory Store (extended for PR tracking)
‚îú‚îÄ‚îÄ code_reviewer.py # LLM-powered code analysis
‚îú‚îÄ‚îÄ code_review_updater.py # Persistent review logging
‚îú‚îÄ‚îÄ readme_updater.py # Smart README updates from diffs
‚îú‚îÄ‚îÄ spec_updater.py # Progress documentation
‚îú‚îÄ‚îÄ github_client.py # GitHub API wrapper (extended for PR operations)
‚îú‚îÄ‚îÄ llm_client.py # OpenAI/Anthropic/Gemini abstraction
‚îú‚îÄ‚îÄ config.py # .env loading + validation (extended for PR config)
‚îî‚îÄ‚îÄ utils.py # Shared utilities

tests/ # pytest tests (mock external services)
dashboard/ # React + Vite dashboard
‚îú‚îÄ‚îÄ App.tsx # Main dashboard component
‚îú‚îÄ‚îÄ services/apiService.ts # FastAPI client
‚îî‚îÄ‚îÄ components/ # UI components
run_api.py # FastAPI server launcher (NEW)
.env.example # Configuration template
requirements.txt # Dependencies
README.md # User documentation
spec.md # Product spec + progress log


## üöÄ Setup & Run

Install
git clone https://github.com/Amitro123/GithubAgent.git
cd GithubAgent
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

Configure
cp .env.example .env

Edit .env: GITHUB_TOKEN, OPENAI_API_KEY, etc.
Run locally
export PYTHONPATH=$PYTHONPATH:$(pwd)/src # Linux/Mac
python -m automation_agent.main # http://localhost:8080/

**Health check**: `curl http://localhost:8080/` ‚Üí `{"status": "ok"}`

## üõ†Ô∏è Core Workflow (NEVER BREAK THIS)

### Push Event Flow
```
GitHub Push Event ‚Üí webhook_server.py/api_server.py
‚Üí Verify HMAC signature ‚Üí extract diff/commit SHA
‚Üí trigger_filter.py ‚Üí classify event + analyze diff
‚Üí IF trivial change: skip automation, log reason
‚Üí ELSE: orchestrator.py ‚Üí run tasks IN PARALLEL:
   ‚Ü≥ code_reviewer.py ‚Üí post comment/issue
   ‚Ü≥ readme_updater.py ‚Üí create PR (if changes)
   ‚Ü≥ spec_updater.py ‚Üí append to spec.md
‚Üí Log results + GitHub artifacts created
```

### Pull Request Event Flow (NEW)
```
GitHub PR Event (opened/synchronized/reopened) ‚Üí api_server.py
‚Üí Verify HMAC signature ‚Üí extract PR number + diff
‚Üí trigger_filter.py ‚Üí classify as pr_opened/pr_synchronized/pr_reopened
‚Üí IF trivial change: skip automation, log reason
‚Üí ELSE: orchestrator.run_automation_with_context():
   ‚Ü≥ code_reviewer.py ‚Üí post PR REVIEW (not commit comment)
   ‚Ü≥ readme_updater.py + spec_updater.py ‚Üí grouped into SINGLE automation PR
‚Üí Session memory tracks: trigger_type, run_type, pr_number, skip_reason
```

**All tasks log execution to `session_memory.py`**

## üìã Agent Task Priorities

When working on this repo, focus on these **in order**:

### 1. **Core Flow Reliability** (Highest priority)
‚úÖ Make webhook ‚Üí orchestrator ‚Üí GitHub side-effects robust
‚úÖ Add retry logic for transient API failures
‚úÖ Make tasks idempotent (handle webhook retries)
‚úÖ Improve error handling + logging
‚úÖ **Error hardening for Jules 404 and LLM 429** (prevents junk PRs, tracks failures)


### 2. **LLM Output Quality**
‚úÖ Better prompts for code review (actionable, structured)
‚úÖ Smarter README change detection (functions/classes/APIs)
‚úÖ spec.md entries: summary + decisions + next steps
‚úÖ Chunk large diffs appropriately


### 3. **Configuration & Extensibility**
‚úÖ Add multi-LLM support (Gemini, local models)
‚úÖ Per-branch policies (stricter on main)
‚úÖ Agent platform integration (Windsurf/AntiGravity hooks)


## üß™ Testing Rules

**ALWAYS test changes with:**
1. Unit tests (mock everything external)
pytest tests/ -v

2. Manual end-to-end
echo "test" >> test.txt
git add test.txt && git commit -m "test automation" && git push

text

**Mock these in tests:**
- `github_client.py` (GitHub API)
- `llm_client.py` (OpenAI/Anthropic)  
- `requests` (webhook simulation)
- `session_memory.py` (Persistence layer)

## üíª Coding Standards

‚úÖ DO: Type hints + Google docstrings
def analyze_diff(diff: str, context: Dict[str, str]) -> str:
"""Analyzes git diff and returns structured review.

Args:
    diff: Raw git diff content
    context: File contents around changes
    
Returns:
    Markdown formatted review string
"""
pass
‚ùå NEVER: print(), hardcoded values, missing types
text

**Dependencies**: Add to `requirements.txt`, never `pip freeze`.

## üîí Security Rules

‚ùå NEVER log:

GITHUB_TOKEN, API keys

Full git diffs (may contain secrets)

Raw webhook payloads

‚úÖ ALWAYS:

Verify webhook HMAC signature

Use minimal GitHub token scopes

Validate/sanitize LLM outputs before posting

Run `bandit -r src/` to check for security issues before pushing code


## üéØ Current spec.md Tasks

Read `spec.md` first, then prioritize:
1. ‚úÖ Core functionality working
2. ‚úÖ Comprehensive testing (Phase 3) - **99/99 tests passing, 100% coverage**
3. ‚úÖ FastAPI + Dashboard Integration
4. ‚úÖ Session Memory & Architecture Diagram
5. ‚úÖ Dashboard Real Data Integration (bugs, PRs, LLM metrics from GitHub API)
6. ‚úÖ Mutation Testing Integration (Linux/Mac/CI only - Windows shows helpful skip message)
7. ‚úÖ GitHub Actions Workflow for Mutation Testing in CI
8. ‚úÖ **PR-Centric Automation** - Trigger on PR events, trivial change filtering, grouped automation PRs
9. üöÄ E2E Testing with ngrok
10. üöÄ Deployment readiness (Phase 4) - Docker + CI/CD


## üß¨ Mutation Testing (Linux/Mac/CI Only)

**Platform Support:**
- ‚úÖ **Linux/Mac**: Full support with mutmut
- ‚úÖ **CI/CD**: Run in Linux runners (GitHub Actions, GitLab CI, etc.)
- ‚ö†Ô∏è  **Windows**: Not supported (mutmut requires Unix `resource` module)
  - API returns: `{"status": "skipped", "reason": "Use WSL or CI"}`
  - Dashboard shows mutation tests are skipped
  - **Solution**: Use WSL, Docker, or run tests in CI

**Configuration:**
```bash
ENABLE_MUTATION_TESTS=True  # Enable feature
MUTATION_MAX_RUNTIME_SECONDS=600  # 10 minute timeout
```

**API Endpoints:**
- `POST /api/mutation/run` - Trigger tests (background task)
- `GET /api/mutation/results` - Fetch latest results
- `GET /api/metrics` - Includes mutation score from cached results

**Results:**
- Cached in `mutation_results.json`
- Displayed in dashboard Code Quality card
- Updated when tests run locally (Linux/Mac) or via CI

**CI/CD Integration:**
- GitHub Actions workflow: `.github/workflows/mutation-tests.yml`
- Runs on push to main or manual trigger
- Saves results as artifacts (30 days)
- Download and copy to repo root for dashboard display
- See `.github/workflows/MUTATION_TESTING.md` for details

## üéØ PR-Centric Configuration (NEW)

**Trigger Modes:**
```bash
TRIGGER_MODE=both    # "pr" = PR events only, "push" = push only, "both" = all events
ENABLE_PR_TRIGGER=True
ENABLE_PUSH_TRIGGER=True
```

**Trivial Change Filter:**
```bash
TRIVIAL_CHANGE_FILTER_ENABLED=True  # Skip automation for trivial changes
TRIVIAL_MAX_LINES=10                 # Max lines for doc-only to be "trivial"
TRIVIAL_DOC_PATHS=README.md,*.md,docs/**  # Patterns for doc files
```

**PR Automation Behavior:**
```bash
GROUP_AUTOMATION_UPDATES=True  # Bundle README+spec into single automation PR
POST_REVIEW_ON_PR=True         # Post code review as PR review (not commit comment)
```

**Run Types (tracked in session_memory):**
- `full_automation` - All tasks run
- `partial_docs_only` - Only doc updates (no code review)
- `skipped_trivial_change` - Skipped due to trivial change filter
- `skipped_docs_only` - Skipped because only docs changed

**New API Endpoints:**
- `GET /api/history/skipped` - Get runs skipped due to trivial changes
- `GET /api/history/pr/{pr_number}` - Get runs for a specific PR
- `GET /api/trigger-config` - Get current trigger configuration

## üö´ DON'T TOUCH (Unless Requested)

‚ùå Don't change webhook payload format
‚ùå Don't remove parallel task execution
‚ùå Don't hardcode config values
‚ùå Don't use print() for logging
‚ùå Don't make real API calls in tests
‚ùå Don't break backward compatibility with push-only workflows



## üìà Success Metrics for Agents

Your changes are successful if:
‚úÖ pytest passes 100%
‚úÖ Local webhook server starts cleanly
‚úÖ Test push ‚Üí 3 tasks complete ‚Üí GitHub artifacts created
‚úÖ Logs are structured + no secrets exposed
‚úÖ README/spec.md stay accurate after changes

### 1. CodeReviewer (`code_reviewer.py`)
- **Role**: Senior Software Engineer / Security Auditor
- **Responsibility**: Analyze git diffs for bugs, security flaws, and style issues.
- **Tools**:
  - `ReviewProvider`: Pluggable review engine (Jules / Google Code Review API or LLM).
  - `LLMClient`: Fallback to Gemini/OpenAI/Anthropic if Jules is unavailable.
  - `GitHubClient`: Post comments/issues.
- **Behavior**:
  - Receives commit SHA.
  - Fetches diff + context.
  - Calls `ReviewProvider.review_code()`.
  - Formats output as markdown.
  - Posts to GitHub.

### 4. CodeReviewUpdater
- **Purpose**: Maintains a persistent log of all code reviews in `AUTOMATED_REVIEWS.md`.
- **Logic**:
  - Runs after `CodeReviewer` completes successfully.
  - Summarizes the full review into a concise entry (Score, Key Issues, Action Items).
  - Appends to `AUTOMATED_REVIEWS.md`.
- **Rules**:
  - Never overwrite the log, always append.
  - If `AUTOMATED_REVIEWS.md` is missing, create it.
  - Use `LLMClient.summarize_review` for consistency.
  - Note: Uses `AUTOMATED_REVIEWS.md` (not `code_review.md`) to avoid collision with `CODE_REVIEW.md` on case-insensitive filesystems.
